{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87a8028-ce51-45e6-9451-65793e6d1324",
   "metadata": {},
   "source": [
    "# LLM Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9725c36-bd64-444a-ade4-42a38119b365",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe13995d-0b3a-468d-8a7c-c6f36969e78c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e49fee1-0e46-40b0-ba4b-0d0cc5ea460a",
   "metadata": {},
   "source": [
    "## Basic Question and Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbdc4de1-24be-4e3d-a4fa-483a4f3cd901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "746be696-6d14-4b7f-9e51-431817c40671",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"gemma:7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "059c51fe-232c-48ae-8d0f-bd3f04dfde4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singapore is a city-state located on the island of Singapore. It is a highly developed country with a strong economy and a high quality of life.\n"
     ]
    }
   ],
   "source": [
    "response = llm.complete(\"What is Singapore?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cee2341f-da02-4b10-86ea-fac4676ac4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Large Language Models (LLMs)** are a type of language model that are trained on massive amounts of text data, typically billions or even trillions of words. LLMs are designed to understand and generate human-like text, and they are often used for a wide range of tasks, including:\n",
      "\n",
      "* **Text summarization:** Converting large amounts of text into shorter summaries.\n",
      "* **Text generation:** Generating new text, such as articles, stories, or code.\n",
      "* **Translation:** Translating text from one language to another.\n",
      "* **Question answering:** Answering questions based on text.\n",
      "* **Code generation:** Generating code in various programming languages.\n",
      "\n",
      "**Key Characteristics of LLMs:**\n",
      "\n",
      "* **Large-scale training:** LLMs are trained on massive datasets, typically billions or trillions of words.\n",
      "* **Text-centric:** LLMs are primarily designed to understand and generate text.\n",
      "* **Multi-task learning:** LLMs can be trained to perform multiple tasks, such as text summarization, translation, and code generation.\n",
      "* **Transfer learning:** LLMs can be fine-tuned for specific tasks, leveraging their general language understanding abilities.\n",
      "* **Human-like text generation:** LLMs can generate text that resembles human writing, often with high accuracy.\n",
      "\n",
      "**Examples of LLMs:**\n",
      "\n",
      "* **GPT-3:** A popular LLM that is known for its ability to generate high-quality text.\n",
      "* **GPT-Neo:** A variant of GPT-3 that is designed for text generation tasks.\n",
      "* **Transformer-XL:** A large language model that is based on the transformer architecture.\n",
      "\n",
      "**Applications:**\n",
      "\n",
      "LLMs have a wide range of potential applications, including:\n",
      "\n",
      "* Text and code editing\n",
      "* Content creation\n",
      "* Information retrieval\n",
      "* Machine translation\n",
      "* Code development\n",
      "* Customer service\n",
      "\n",
      "**Note:** LLMs are still under development, and their capabilities are constantly evolving.\n"
     ]
    }
   ],
   "source": [
    "response = llm.complete(\"What is a Large Language Model?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b3a912-7f5f-44c6-aa9d-361ef008880c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e42a33fd-aed7-4717-97f3-1f3a68014d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy Birthday, [Friend's Name]! I hope your day is filled with joy, laughter, and happiness. May all your wishes come true!\n"
     ]
    }
   ],
   "source": [
    "# Set the prompt\n",
    "prompt = \"Write a happy birthday message, I would like to send to my friend.\"\n",
    "\n",
    "# Set the temperature\n",
    "# Higher values (e.g., 1.0) make the output more random, while lower values (e.g., 0.2) make it more deterministic\n",
    "temperature = 0.9\n",
    "\n",
    "# Set the top_k\n",
    "# This parameter controls the number of tokens considered for each step of the generation process\n",
    "top_k = 50\n",
    "\n",
    "# Set the max tokens\n",
    "# This parameter controls the maximum length of the generated text\n",
    "max_tokens = 300\n",
    "\n",
    "# Generate the response\n",
    "response = llm.complete(prompt, temperature=temperature, top_k=top_k, max_tokens=max_tokens)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f286884-232a-410d-bef1-3fb78724cce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few options for a happy birthday message you could send to your friend:\n",
      "\n",
      "**Short and sweet:**\n",
      "\n",
      "* \"Happy Birthday, [friend's name]! Wishing you a day filled with joy and happiness.\"\n",
      "* \"Have a very happy birthday, [friend's name]! May all your wishes come true.\"\n",
      "* \"Sending you warm wishes on your special day, [friend's name]. Have a great time!\"\n",
      "\n",
      "**Personalized:**\n",
      "\n",
      "* \"Happy Birthday, [friend's name]! I hope your day is as bright as your smile.\"\n",
      "* \"Hope your birthday is filled with [friend's favorite things], [friend's name]. Wishing you a happy and healthy one!\"\n",
      "* \"Happy Birthday, [friend's name]! I'm so glad we're celebrating your special day together.\"\n",
      "\n",
      "**Funny:**\n",
      "\n",
      "* \"Happy Birthday, [friend's name]! I hope your day is filled with cake and good times... even if it's not my cake.\"\n",
      "* \"Have a very happy birthday, [friend's name]! I'm not even going to ask how old you are.\"\n",
      "* \"Wishing you a happy birthday, [friend's name]. May your day be filled with laughter and mischief.\"\n",
      "\n",
      "**Creative:**\n",
      "\n",
      "* \"Happy Birthday, [friend's name]! May your day be filled with sprinkles and surprises.\"\n",
      "* \"May your day be filled with happiness and a sprinkle of magic, [friend's name].\"\n",
      "* \"Have a birthday as dazzling as a shooting star, [friend's name]. Make a wish!\"\n",
      "\n",
      "**Remember:**\n",
      "\n",
      "* You can personalize the message to your friend's interests and humor.\n",
      "* You can add a custom touch, such as mentioning a shared memory or inside joke.\n",
      "* You can keep the message short and sweet, or write a longer, more heartfelt message.\n",
      "\n",
      "**Most importantly, remember to include your own personal touch and make the message your own.**\n"
     ]
    }
   ],
   "source": [
    "# Set the prompt\n",
    "prompt = \"Write a happy birthday message, I would like to send to my friend.\"\n",
    "\n",
    "# Set the temperature\n",
    "# Higher values (e.g., 1.0) make the output more random, while lower values (e.g., 0.2) make it more deterministic\n",
    "temperature = 1.0\n",
    "\n",
    "# Set the top_k\n",
    "# This parameter controls the number of tokens considered for each step of the generation process\n",
    "top_k = 50\n",
    "\n",
    "# Set the max tokens\n",
    "# This parameter controls the maximum length of the generated text\n",
    "max_tokens = 300\n",
    "\n",
    "# Generate the response\n",
    "response = llm.complete(prompt, temperature=temperature, top_k=top_k, max_tokens=max_tokens)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a978ba83-574e-48c6-823d-a804af7b9c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1fd89f-50ca-44c4-89c0-2ba1209e382b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d2191-7644-4624-a1af-b8d578c95ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84febe7c-a426-47e8-9257-312c54e92cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
